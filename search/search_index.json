{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DDLCheck","text":"<p>DDLCheck is a tool that scans PostgreSQL SQL migration files for potentially risky operations that could cause downtime, data loss, or other issues in production environments.</p>"},{"location":"#overview","title":"Overview","text":"<p>Database migrations can be risky, especially in production environments with large tables and high traffic. DDLCheck analyzes your SQL migrations to identify operations that:</p> <ul> <li>Cause table rewrites (ALTER COLUMN TYPE, DROP COLUMN)</li> <li>Acquire excessive locks (non-CONCURRENT indexes, SET NOT NULL)</li> <li>May lead to data loss (DROP TABLE, TRUNCATE)</li> <li>Affect all rows without filtering (UPDATE without WHERE)</li> </ul> <p>The goal is to help database administrators and developers make informed decisions about their migrations, avoiding unintended consequences and planning for potentially risky operations.</p>"},{"location":"#why-use-ddlcheck","title":"Why Use DDLCheck?","text":"<ul> <li>Prevent Downtime: Avoid operations that lock tables for extended periods</li> <li>Prevent Data Loss: Identify destructive operations before they run</li> <li>Education: Learn about PostgreSQL's behavior with different operations</li> <li>Best Practices: Follow community-established patterns for safer migrations</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install\npip install ddlcheck\n\n# Check a single SQL file\nddlcheck check migration.sql\n\n# Check a directory of SQL files\nddlcheck check migrations/\n\n# List all available checks\nddlcheck list-checks\n\n# Show version\nddlcheck version\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Suppose you have a migration file <code>migration.sql</code> with the following content:</p> <pre><code>-- Add a new column with NOT NULL and DEFAULT\nALTER TABLE users ADD COLUMN email_verified BOOLEAN NOT NULL DEFAULT FALSE;\n\n-- Create an index without CONCURRENTLY\nCREATE INDEX idx_users_email ON users (email);\n\n-- Update all rows without a WHERE clause\nUPDATE products SET visible = TRUE;\n</code></pre> <p>Running DDLCheck against this file:</p> <pre><code>ddlcheck check migration.sql\n</code></pre> <p>Will give you output like:</p> <pre><code>File: migration.sql\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Line \u2503 Severity \u2503 Check      \u2503 Message                                                                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1    \u2502 HIGH     \u2502 add_column \u2502 Column 'email_verified' added to table 'users' with NOT NULL and DEFAULT   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSuggestion for add_column (line 1):\nConsider using two separate migrations:\n1. First add the column with a DEFAULT but as nullable\n2. After data has been populated, add the NOT NULL constraint\n\n... (additional output omitted) ...\n</code></pre> <p>This helps you identify potential issues before running the migration and suggests safer alternatives.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Multiple Check Types: Includes checks for various risky PostgreSQL operations</li> <li>Configurable: Customize which checks to run and their severity</li> <li>Helpful Suggestions: Provides alternatives to risky operations</li> <li>Line Numbers: Identifies exactly where issues occur</li> <li>Exit Codes: Returns non-zero exit code when issues are found (useful for CI pipelines)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation</li> <li>Available Checks</li> <li>Configuration</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! See the GitHub repository for details on how to contribute. </p>"},{"location":"configuration/","title":"Configuration","text":"<p>DDLCheck can be configured using a TOML configuration file. By default, it looks for a file named <code>.ddlcheck</code> in the current directory, but you can specify a different file using the <code>--config</code> option.</p>"},{"location":"configuration/#configuration-file-format","title":"Configuration File Format","text":"<p>DDLCheck uses TOML format for configuration. Here's an example configuration file:</p> <pre><code># List of check IDs to disable\nexcluded_checks = [\"drop_table\", \"truncate\"]\n\n# Override severity levels\n[severity]\ncreate_index = \"LOW\"\nadd_column = \"HIGH\"\n\n# Individual check configurations\n[create_index]\nignore_non_concurrent = false\nmin_size_warning = 1000  # Only warn for tables likely larger than this\n\n[update_without_filter]\nallowed_tables = [\"config\", \"settings\"]  # Tables that are safe to update without filters\n\n[truncate]\nallowed_tables = [\"logs_temp\", \"imports_staging\"]  # Tables that are safe to truncate\n</code></pre>"},{"location":"configuration/#available-configuration-options","title":"Available Configuration Options","text":""},{"location":"configuration/#global-options","title":"Global Options","text":"Option Type Description <code>excluded_checks</code> List[str] List of check IDs to disable"},{"location":"configuration/#severity-overrides","title":"Severity Overrides","text":"<p>You can override the default severity level for any check by adding a section under <code>[severity]</code>:</p> <pre><code>[severity]\ncheck_id = \"SEVERITY\"  # HIGH, MEDIUM, LOW, or INFO\n</code></pre>"},{"location":"configuration/#check-specific-options","title":"Check-Specific Options","text":""},{"location":"configuration/#createindexcheck-create_index","title":"CreateIndexCheck (<code>create_index</code>)","text":"Option Type Default Description <code>ignore_non_concurrent</code> bool <code>false</code> Completely ignore non-concurrent indexes <code>min_size_warning</code> int <code>0</code> Only warn for tables likely larger than this row count (0 means all)"},{"location":"configuration/#updatewithoutfiltercheck-update_without_filter","title":"UpdateWithoutFilterCheck (<code>update_without_filter</code>)","text":"Option Type Default Description <code>allowed_tables</code> List[str] <code>[]</code> Tables that are safe to update without WHERE clauses"},{"location":"configuration/#truncatecheck-truncate","title":"TruncateCheck (<code>truncate</code>)","text":"Option Type Default Description <code>allowed_tables</code> List[str] <code>[]</code> Tables that are safe to truncate"},{"location":"configuration/#command-line-configuration","title":"Command Line Configuration","text":"<p>You can also override some configuration options from the command line:</p> <pre><code># Exclude checks by ID\nddlcheck check --exclude add_column,drop_table migration.sql\n\n# Specify a custom config file\nddlcheck check --config my_custom_config.toml migration.sql\n\n# Enable verbose logging\nddlcheck check --verbose migration.sql\n\n# Write logs to a file\nddlcheck check --log-file ddlcheck.log migration.sql\n</code></pre>"},{"location":"configuration/#configuration-precedence","title":"Configuration Precedence","text":"<p>Configuration options are applied in the following order (each one overrides the previous):</p> <ol> <li>Default values</li> <li>Configuration file</li> <li>Command line arguments </li> </ol>"},{"location":"configuration/#example-with-configuration","title":"Example with Configuration","text":"<p>Here's an example of running DDLCheck with a configuration file:</p> <pre><code>$ cat .ddlcheck\n# DDLCheck configuration\nexcluded_checks = [\"create_index\", \"rename_column\"]\n\n[severity]\ntruncate = \"MEDIUM\"\n\n[add_column]\nignore_with_default = true</code></pre> <p>Running DDLCheck with this configuration:</p> <pre><code>$ ddlcheck check migration.sql\nChecking 1 SQL files...\n2025-04-24 19:15:22 - ddlcheck.cli - INFO - Found 1 SQL files to check\n\nFile: migration.sql (example.sql)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Line \u2503 Severity \u2503 Check            \u2503 Message                                          \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 3    \u2502 MEDIUM   \u2502 truncate         \u2502 TRUNCATE operation on table 'audit_logs'         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Suggestion for truncate (line 3) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 TRUNCATE operation on table 'audit_logs'                                               \u2502\n\u2502                                                                                        \u2502\n\u2502 TRUNCATE is a destructive operation that removes all rows                              \u2502\n\u2502 from a table. Consider using DELETE with a WHERE clause or                             \u2502\n\u2502 dropping and recreating the table if it's temporary data.                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nFound 1 issue!\n2025-04-24 19:15:22 - ddlcheck.cli - INFO - Found 1 issue</code></pre> <p>Note that with this configuration:</p> <ol> <li>The <code>create_index</code> and <code>rename_column</code> checks are excluded</li> <li>The severity of the <code>truncate</code> check is reduced from HIGH to MEDIUM</li> <li>The <code>add_column</code> check is configured to ignore columns added with a default value </li> </ol>"},{"location":"custom_checks/","title":"Creating Custom Checks","text":"<p>DDLCheck can be extended with custom checks to fit your organization's specific needs and database practices.</p>"},{"location":"custom_checks/#custom-check-basics","title":"Custom Check Basics","text":"<p>A check in DDLCheck is a Python class that:</p> <ol> <li>Extends the <code>Check</code> base class</li> <li>Implements required properties (<code>id</code>, <code>description</code>, <code>severity</code>)</li> <li>Implements the <code>check_statement</code> method to analyze SQL statements</li> </ol>"},{"location":"custom_checks/#creating-a-custom-check","title":"Creating a Custom Check","text":""},{"location":"custom_checks/#1-create-a-new-python-file","title":"1. Create a New Python File","text":"<p>Create a new file for your custom check, either: - Inside the DDLCheck package (if contributing to the project) - In your own package or script (if extending for your specific use case)</p>"},{"location":"custom_checks/#2-implement-the-check-class","title":"2. Implement the Check Class","text":"<p>Here's a template for a custom check:</p> <pre><code>\"\"\"Custom check for something specific to your organization.\"\"\"\n\nfrom typing import Any, Dict, List\n\nfrom ddlcheck.core import Check\nfrom ddlcheck.models import Issue, SeverityLevel\n\n\nclass MyCustomCheck(Check):\n    \"\"\"Check for something specific to your organization.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the unique identifier for this check.\"\"\"\n        return \"my_custom_check\"\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Return a description of what this check looks for.\"\"\"\n        return \"Detects something specific to your organization\"\n\n    @property\n    def severity(self) -&gt; SeverityLevel:\n        \"\"\"Return the default severity level for issues found by this check.\"\"\"\n        return SeverityLevel.MEDIUM\n\n    def check_statement(self, stmt: Dict[str, Any], line: int) -&gt; List[Issue]:\n        \"\"\"Check a single SQL statement for issues.\n\n        Args:\n            stmt: The parsed SQL statement\n            line: The line number where the statement begins\n\n        Returns:\n            List of issues found in the statement\n        \"\"\"\n        issues = []\n\n        # Implement your custom check logic here\n        # Example: Check if a statement contains a specific table\n\n        # if \"some_condition\":\n        #     issues.append(\n        #         self.create_issue(\n        #             message=\"Message describing the issue\",\n        #             line=line,\n        #             suggestion=\"Suggestion for how to fix it\",\n        #         )\n        #     )\n\n        return issues\n</code></pre>"},{"location":"custom_checks/#3-register-your-custom-check","title":"3. Register Your Custom Check","text":"<p>To use your custom check with DDLCheck, you need to register it in one of the following ways:</p>"},{"location":"custom_checks/#option-1-extend-the-checks-module","title":"Option 1: Extend the checks module","text":"<p>If you're contributing to DDLCheck itself, add your check to the <code>ALL_CHECKS</code> list in <code>src/ddlcheck/checks/__init__.py</code>:</p> <pre><code>from ddlcheck.checks.my_custom_check import MyCustomCheck\n\n# List of all available checks\nALL_CHECKS = [\n    # ... existing checks ...\n    MyCustomCheck,\n]\n</code></pre>"},{"location":"custom_checks/#option-2-use-a-plugin-system-future-feature","title":"Option 2: Use a plugin system (future feature)","text":"<p>In the future, DDLCheck may support a plugin system to load custom checks without modifying the core code.</p>"},{"location":"custom_checks/#option-3-create-a-custom-entry-point","title":"Option 3: Create a custom entry point","text":"<p>You can create your own script that imports DDLCheck and registers your custom checks:</p> <pre><code>#!/usr/bin/env python\n\nfrom ddlcheck.cli import app\nfrom ddlcheck.checks import ALL_CHECKS\nfrom my_module.my_custom_check import MyCustomCheck\n\n# Add your custom check\nALL_CHECKS.append(MyCustomCheck)\n\nif __name__ == \"__main__\":\n    app()\n</code></pre>"},{"location":"custom_checks/#sql-statement-structure","title":"SQL Statement Structure","text":"<p>The <code>stmt</code> parameter passed to <code>check_statement</code> is a dictionary representation of the parsed SQL AST (Abstract Syntax Tree) using the pglast library.</p> <p>The structure varies based on the statement type:</p> <ul> <li>The key is the statement type (e.g., <code>\"SelectStmt\"</code>, <code>\"AlterTableStmt\"</code>, <code>\"CreateIndexStmt\"</code>)</li> <li>The value is the parsed statement object with properties specific to that statement type</li> </ul> <p>To understand the statement structure for your custom check, it can be helpful to:</p> <ol> <li>Use print debugging: <code>print(stmt)</code> to see the full structure</li> <li>Check existing checks for similar SQL statements</li> <li>Refer to the PostgreSQL parser source code for detailed node definitions </li> </ol>"},{"location":"development/","title":"Development","text":"<p>This guide explains how to set up your development environment and contribute to DDLCheck.</p>"},{"location":"development/#setting-up","title":"Setting Up","text":"<ol> <li>Clone the repository</li> </ol> <pre><code>git clone https://github.com/olirice/ddlcheck.git\ncd ddlcheck\n</code></pre> <ol> <li>Install Poetry</li> </ol> <p>DDLCheck uses Poetry for dependency management. If you don't have Poetry installed:</p> <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>poetry install\n</code></pre> <ol> <li>Activate virtual environment</li> </ol> <pre><code>poetry shell\n</code></pre>"},{"location":"development/#development-tasks","title":"Development Tasks","text":""},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npoetry run pytest\n\n# Run with coverage report\npoetry run pytest --cov=src/ddlcheck --cov-report=term-missing\n</code></pre>"},{"location":"development/#building-documentation","title":"Building Documentation","text":"<pre><code># Build documentation\npoetry run mkdocs build\n\n# Serve documentation locally\npoetry run mkdocs serve\n</code></pre>"},{"location":"development/#code-quality-tools","title":"Code Quality Tools","text":"<p>DDLCheck uses several tools to ensure code quality:</p> <pre><code># Run linting\npoetry run flake8\n\n# Run type checking\npoetry run mypy src\n\n# Run all pre-commit hooks\npoetry run pre-commit run --all-files\n</code></pre>"},{"location":"development/#creating-a-new-check","title":"Creating a New Check","text":"<p>To create a new check:</p> <ol> <li>Create a new file in <code>src/ddlcheck/checks/my_check.py</code></li> <li>Implement the check class by extending the <code>Check</code> base class</li> <li>Add your check to <code>ALL_CHECKS</code> in <code>src/ddlcheck/checks/__init__.py</code></li> <li>Add tests in <code>tests/checks/test_my_check.py</code></li> <li>Add documentation in <code>docs/checks/my_check.md</code></li> </ol> <p>Example of a check implementation:</p> <pre><code>\"\"\"Check for something risky.\"\"\"\n\nfrom typing import Any, Dict, List\n\nfrom ddlcheck.core import Check\nfrom ddlcheck.models import Issue, SeverityLevel\n\n\nclass MyCheck(Check):\n    \"\"\"Check for something risky.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Return the unique identifier for this check.\"\"\"\n        return \"my_check\"\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Return a description of what this check looks for.\"\"\"\n        return \"Detects something risky that could cause issues\"\n\n    @property\n    def severity(self) -&gt; SeverityLevel:\n        \"\"\"Return the default severity level for issues found by this check.\"\"\"\n        return SeverityLevel.MEDIUM\n\n    def check_statement(self, stmt: Dict[str, Any], line: int) -&gt; List[Issue]:\n        \"\"\"Check a single SQL statement for issues.\n\n        Args:\n            stmt: The parsed SQL statement\n            line: The line number where the statement begins\n\n        Returns:\n            List of issues found in the statement\n        \"\"\"\n        issues = []\n\n        # Check logic here...\n\n        if issue_detected:\n            issues.append(\n                self.create_issue(\n                    message=\"Something risky was detected\",\n                    line=line,\n                    suggestion=\"Here's how to fix it\",\n                )\n            )\n\n        return issues\n</code></pre>"},{"location":"development/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>src/ddlcheck/__init__.py</code></li> <li>Update CHANGELOG.md</li> <li>Create a new release on GitHub</li> <li>The package will be automatically published to PyPI </li> </ol>"},{"location":"installation/","title":"Installation","text":"<p>DDLCheck requires Python 3.12 or newer. It's designed to be easy to install and integrate into your existing workflows.</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<p>You can install DDLCheck using pip:</p> <pre><code>pip install ddlcheck\n</code></pre> <p>This will install DDLCheck and all its dependencies.</p>"},{"location":"installation/#from-source","title":"From Source","text":"<p>To install from source:</p> <pre><code># Clone the repository\ngit clone https://github.com/olirice/ddlcheck.git\ncd ddlcheck\npip install .\n</code></pre>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>Once installed, verify the installation by running:</p> <pre><code>ddlcheck version\n</code></pre> <p>You should see the version number of DDLCheck.</p>"},{"location":"usage/","title":"Usage","text":"<p>DDLCheck provides a command-line interface (CLI) for checking SQL files for potentially dangerous operations.</p>"},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<p>To check a single SQL file:</p> <pre><code>ddlcheck check path/to/file.sql\n</code></pre> <p>To check all SQL files in a directory (recursively):</p> <pre><code>ddlcheck check path/to/directory\n</code></pre>"},{"location":"usage/#command-line-options","title":"Command Line Options","text":"<p>DDLCheck provides several command-line options to customize its behavior:</p> Option Description <code>--exclude</code>, <code>-e</code> Comma-separated list of checks to exclude <code>--config</code>, <code>-c</code> Path to configuration file (default: <code>.ddlcheck</code>) <code>--verbose</code>, <code>-v</code> Enable verbose output <code>--log-file</code> Path to log file"},{"location":"usage/#examples","title":"Examples","text":"<p>Exclude specific checks:</p> <pre><code>ddlcheck check --exclude add_column,truncate path/to/file.sql\n</code></pre> <p>Use a custom configuration file:</p> <pre><code>ddlcheck check --config my_config.toml path/to/file.sql\n</code></pre> <p>Enable verbose output:</p> <pre><code>ddlcheck check --verbose path/to/file.sql\n</code></pre>"},{"location":"usage/#available-commands","title":"Available Commands","text":"Command Description <code>check</code> Check SQL files for potential issues <code>list-checks</code> List all available checks <code>version</code> Show version information"},{"location":"usage/#examples_1","title":"Examples","text":"<p>List all available checks:</p> <pre><code>$ ddlcheck list-checks\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ID                 \u2503 Description                                                     \u2503 Severity \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 add_column         \u2502 Detects ALTER TABLE ADD COLUMN operations                       \u2502 HIGH     \u2502\n\u2502 alter_column_type  \u2502 Detects ALTER TABLE ALTER COLUMN TYPE operations                \u2502 HIGH     \u2502\n\u2502 create_index       \u2502 Detects CREATE INDEX operations without CONCURRENTLY            \u2502 MEDIUM   \u2502\n\u2502 drop_column        \u2502 Detects ALTER TABLE DROP COLUMN operations                      \u2502 HIGH     \u2502\n\u2502 drop_table         \u2502 Detects DROP TABLE operations that could result in data loss    \u2502 HIGH     \u2502\n\u2502 rename_column      \u2502 Detects ALTER TABLE RENAME COLUMN operations                    \u2502 MEDIUM   \u2502\n\u2502 set_not_null       \u2502 Detects ALTER TABLE SET NOT NULL operations                     \u2502 MEDIUM   \u2502\n\u2502 truncate           \u2502 Detects TRUNCATE TABLE operations                               \u2502 HIGH     \u2502\n\u2502 update_without_filter \u2502 Detects UPDATE statements without a WHERE clause             \u2502 HIGH     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</code></pre> <p>Show version information:</p> <pre><code>$ ddlcheck version\nDDLCheck version 0.1.0</code></pre>"},{"location":"usage/#example-output","title":"Example Output","text":"<p>When checking a SQL file with issues, DDLCheck provides detailed output with highlighted issues:</p> <pre><code>$ ddlcheck check risky_operations.sql\nChecking 1 SQL files...\n2025-04-24 18:53:13 - ddlcheck.cli - INFO - Found 1 SQL files to check\n\nFile: risky_operations.sql\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Line \u2503 Severity \u2503 Check                 \u2503 Message                                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1    \u2502 HIGH     \u2502 update_without_filter \u2502 UPDATE statement on table 'products'       \u2502\n\u2502      \u2502          \u2502                       \u2502 without WHERE clause                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Suggestion for update_without_filter (line 1) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 UPDATE statement on table 'products' without WHERE clause                            \u2502\n\u2502                                                                                      \u2502\n\u2502 Add a WHERE clause to limit the rows affected by the update.                         \u2502\n\u2502 Updating all rows in a table can cause excessive I/O and blocking.                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nFound 1 issue!\n2025-04-24 18:53:13 - ddlcheck.cli - INFO - Found 1 issue</code></pre>"},{"location":"checks/","title":"Available Checks","text":"<p>DDLCheck includes several checks for common database schema migration issues. Each check looks for a specific pattern in your SQL that might cause problems in production.</p>"},{"location":"checks/#check-categories","title":"Check Categories","text":"<p>The checks are organized into the following categories:</p>"},{"location":"checks/#high-severity","title":"High Severity","text":"<p>These checks identify operations that can cause significant issues:</p> <ul> <li>add_column_not_null_default: Detects when columns are added with NOT NULL constraints and DEFAULT values</li> <li>alter_column_type: Detects ALTER COLUMN TYPE operations that require table rewrites</li> <li>drop_table: Detects DROP TABLE operations that could result in data loss</li> <li>truncate: Detects TRUNCATE operations which can cause data loss and locks</li> <li>update_without_filter: Detects UPDATE statements without WHERE clauses</li> </ul>"},{"location":"checks/#medium-severity","title":"Medium Severity","text":"<p>These checks identify operations that can cause moderate issues:</p> <ul> <li>create_index: Detects index creation without the CONCURRENTLY option</li> <li>drop_column: Detects DROP COLUMN operations that require table rewrites</li> <li>rename_column: Detects column renames that can break dependent objects</li> <li>set_not_null: Detects when NOT NULL constraints are added to existing columns</li> </ul>"},{"location":"checks/#configuration","title":"Configuration","text":"<p>You can configure or disable any check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Exclude specific checks\nexcluded_checks = [\"truncate\", \"drop_table\"]\n\n# Override severity levels\n[severity]\ncreate_index = \"LOW\"\nadd_column_not_null_default = \"HIGH\"\n\n# Configure individual checks\n[create_index]\nignore_non_concurrent = false\nmin_size_warning = 1000\n\n[update_without_filter]\nallowed_tables = [\"config\", \"settings\"]\n</code></pre> <p>See the Configuration section for more details.</p>"},{"location":"checks/#custom-checks","title":"Custom Checks","text":"<p>You can create your own custom checks by implementing the <code>Check</code> base class. See the Custom Checks section for more information.</p> <pre><code>from ddlcheck.core import Check\nfrom ddlcheck.models import Issue, SeverityLevel\n\nclass MyCustomCheck(Check):\n    \"\"\"A custom check implementation.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        return \"my_custom_check\"\n\n    @property\n    def description(self) -&gt; str:\n        return \"Detects something important\"\n\n    @property\n    def severity(self) -&gt; SeverityLevel:\n        return SeverityLevel.HIGH\n\n    def check_statement(self, stmt, line):\n        # Your implementation here\n        return []\n</code></pre>"},{"location":"checks/add_column/","title":"Add Column Check","text":"<p>Check ID: <code>add_column_not_null_default</code> | Severity: HIGH</p>"},{"location":"checks/add_column/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when columns are added with both a <code>NOT NULL</code> constraint and a <code>DEFAULT</code> value in the same statement.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE users ADD COLUMN email_verified BOOLEAN NOT NULL DEFAULT FALSE;\n</code></pre>"},{"location":"checks/add_column/#why-its-risky","title":"Why Its Risky","text":"<p>When you add a column with both <code>NOT NULL</code> and <code>DEFAULT</code> constraints, PostgreSQL has to perform the following operations:</p> <ol> <li>Take an ACCESS EXCLUSIVE lock on the table (blocks all queries)</li> <li>Add the column to the table metadata</li> <li>Update every row in the table to set the default value</li> <li>Add the NOT NULL constraint</li> </ol> <p>For large tables, this can cause significant downtime because the table is locked for the entire operation. The larger the table, the longer the lock is held.</p>"},{"location":"checks/add_column/#safer-alternative","title":"Safer Alternative","text":"<p>Split this operation into two separate migrations:</p> <p>First migration:</p> <pre><code>-- Add the column as nullable with a default value\nALTER TABLE users ADD COLUMN email_verified BOOLEAN DEFAULT FALSE;\n</code></pre> <p>Second migration (after the first has been applied and data is populated):</p> <pre><code>-- Set the NOT NULL constraint separately\nALTER TABLE users ALTER COLUMN email_verified SET NOT NULL;\n</code></pre> <p>This approach:</p> <ol> <li>Adds the column with a default value which is a metadata-only operation</li> <li>Allows new rows to be inserted with the default value</li> <li>Sets the NOT NULL constraint separately, which still requires a full table scan but is a separate operation</li> </ol>"},{"location":"checks/add_column/#configuration-options","title":"Configuration Options","text":"<p>None specific to this check. </p>"},{"location":"checks/alter_column_type/","title":"Alter Column Type Check","text":"<p>Check ID: <code>alter_column_type</code> | Severity: HIGH</p>"},{"location":"checks/alter_column_type/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when column types are changed using <code>ALTER TABLE ... ALTER COLUMN ... TYPE</code>. This operation requires a table rewrite in PostgreSQL, which can cause locks and downtime for large tables.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE orders ALTER COLUMN status TYPE VARCHAR(100);\n</code></pre> <p>or statements with USING clause:</p> <pre><code>ALTER TABLE orders ALTER COLUMN amount TYPE NUMERIC(10,2) USING amount::NUMERIC(10,2);\n</code></pre>"},{"location":"checks/alter_column_type/#why-its-risky","title":"Why Its Risky","text":"<p>Changing a column's data type in PostgreSQL requires rewriting the entire table because:</p> <ol> <li>PostgreSQL needs to scan every row to validate the conversion</li> <li>This operation takes an ACCESS EXCLUSIVE lock on the table</li> <li>For large tables, this can lead to significant downtime</li> <li>Applications may experience timeouts or failures during the operation</li> </ol>"},{"location":"checks/alter_column_type/#safer-alternative","title":"Safer Alternative","text":"<p>Instead of directly changing the column type, consider a multi-step approach:</p> <ol> <li>Add a new column with the desired type</li> <li>Update data in batches, populating the new column with converted values</li> <li>Update application code to use both columns during transition</li> <li>Once all data is migrated, drop the old column</li> <li>Rename the new column to the original name (if needed)</li> </ol> <p>Example:</p> <pre><code>-- Step 1: Add new column\nALTER TABLE orders ADD COLUMN status_new VARCHAR(100);\n\n-- Step 2: Fill new column in batches (do this in application code or using a cursor)\nUPDATE orders SET status_new = status::VARCHAR(100) WHERE id BETWEEN 1 AND 10000;\n-- ...repeat for all batches\n\n-- Step 3: Validation (in application code)\n\n-- Step 4: Once validated, drop old column\nALTER TABLE orders DROP COLUMN status;\n\n-- Step 5: Rename new column to original name\nALTER TABLE orders RENAME COLUMN status_new TO status;\n</code></pre>"},{"location":"checks/alter_column_type/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"alter_column_type\"]\n\n# Override severity level\n[severity]\nalter_column_type = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n</code></pre>"},{"location":"checks/create_index/","title":"Create Index Check","text":"<p>Check ID: <code>create_index</code> | Severity: MEDIUM</p>"},{"location":"checks/create_index/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when indexes are created without the <code>CONCURRENTLY</code> option.</p> <p>Example risky SQL:</p> <pre><code>CREATE INDEX idx_users_email ON users (email);\n</code></pre>"},{"location":"checks/create_index/#why-its-risky","title":"Why Its Risky","text":"<p>When you create an index without the <code>CONCURRENTLY</code> option, PostgreSQL takes an <code>EXCLUSIVE</code> lock on the table while building the index. This lock blocks all writes to the table (such as INSERT, UPDATE, DELETE operations) until the index is fully built.</p> <p>For large tables, index creation can take a long time, potentially causing:</p> <ol> <li>Application timeouts or failures due to blocked write operations</li> <li>Growing lock queues that affect database performance </li> <li>Elevated latency for application queries</li> </ol>"},{"location":"checks/create_index/#safer-alternative","title":"Safer Alternative","text":"<p>Use the <code>CONCURRENTLY</code> option when creating indexes in production:</p> <pre><code>CREATE INDEX CONCURRENTLY idx_users_email ON users (email);\n</code></pre> <p>The <code>CONCURRENTLY</code> option:</p> <ol> <li>Uses a less restrictive lock that allows writes to continue</li> <li>Takes longer to complete since it does multiple passes over the table</li> <li>Cannot be used within a transaction block</li> </ol> <p>Note that <code>CREATE INDEX CONCURRENTLY</code> is more expensive and slower but greatly reduces the impact on active production applications.</p> <p>When using <code>CREATE INDEX CONCURRENTLY</code>:</p> <ol> <li>You cannot use it inside a transaction block</li> <li>If the operation fails, you may be left with an invalid index that needs to be dropped</li> <li>It places a higher load on the database during creation</li> </ol>"},{"location":"checks/create_index/#configuration-options","title":"Configuration Options","text":"<p>No specific configuration options for this check. </p>"},{"location":"checks/drop_column/","title":"Drop Column Check","text":"<p>Check ID: <code>drop_column</code> | Severity: HIGH</p>"},{"location":"checks/drop_column/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects <code>ALTER TABLE ... DROP COLUMN</code> operations which could potentially cause data loss, application errors, and table locks.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE users DROP COLUMN email;\n</code></pre>"},{"location":"checks/drop_column/#why-its-risky","title":"Why Its Risky","text":"<p>Dropping a column is a high-risk operation because:</p> <ol> <li>It permanently deletes all data stored in the column</li> <li>It cannot be easily reversed without a proper backup</li> <li>It can cause application errors if code still references the column</li> <li>For PostgreSQL versions before 11, dropping a column requires a table rewrite and an ACCESS EXCLUSIVE lock</li> <li>It may impact dependent objects like indexes, constraints, and views</li> </ol>"},{"location":"checks/drop_column/#safer-alternative","title":"Safer Alternative","text":"<p>Instead of immediately dropping columns, consider:</p> <ol> <li>Soft deprecation: First rename the column (e.g., add 'deprecated_' prefix) and stop using it in application code</li> <li>Two-phase migration: First update all application code to stop using the column, then drop it</li> <li>Use transaction: Always use transactions when dropping columns to ensure atomicity</li> </ol> <p>Example safer approach:</p> <pre><code>-- 1. First rename the column to mark it as deprecated\nALTER TABLE users RENAME COLUMN email TO deprecated_email;\n\n-- 2. In a later migration (after confirming no issues):\nALTER TABLE users DROP COLUMN deprecated_email;\n</code></pre>"},{"location":"checks/drop_column/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"drop_column\"]\n\n# Override severity level\n[severity]\ndrop_column = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n</code></pre>"},{"location":"checks/drop_table/","title":"Drop Table Check","text":"<p>Check ID: <code>drop_table</code> | Severity: HIGH</p>"},{"location":"checks/drop_table/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects <code>DROP TABLE</code> operations which could potentially cause data loss and application errors.</p> <p>Example risky SQL:</p> <pre><code>DROP TABLE customers;\n</code></pre>"},{"location":"checks/drop_table/#why-its-risky","title":"Why Its Risky","text":"<p>Dropping a table is a high-risk operation because:</p> <ol> <li>It permanently deletes all data stored in the table</li> <li>It cannot be easily reversed without a proper backup</li> <li>It can cause application errors if code still references the table</li> <li>It may impact dependent objects like views, functions, and triggers</li> </ol>"},{"location":"checks/drop_table/#safer-alternative","title":"Safer Alternative","text":"<p>Instead of immediately dropping tables, consider:</p> <ol> <li>Rename instead of drop: Temporarily rename the table (e.g., add '_bak' suffix) to ensure no issues before permanently dropping it</li> <li>Two-step migration: First remove all application references to the table, then drop it in a separate migration</li> <li>Use IF EXISTS: Always use <code>DROP TABLE IF EXISTS</code> to prevent errors if the table doesn't exist</li> <li>Consider dependencies: Check for and handle dependent objects before dropping tables</li> </ol> <p>Example safer approach:</p> <pre><code>-- 1. First rename the table to mark it for deletion\nALTER TABLE customers RENAME TO customers_to_delete;\n\n-- 2. In a later migration (after confirming no issues):\nDROP TABLE IF EXISTS customers_to_delete;\n</code></pre>"},{"location":"checks/drop_table/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"drop_table\"]\n\n# Override severity level\n[severity]\ndrop_table = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n</code></pre>"},{"location":"checks/rename_column/","title":"Rename Column Check","text":"<p>Check ID: <code>rename_column</code> | Severity: MEDIUM</p>"},{"location":"checks/rename_column/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects <code>ALTER TABLE ... RENAME COLUMN</code> operations which could potentially cause application errors if code still references the old column name.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE users RENAME COLUMN phone TO phone_number;\n</code></pre>"},{"location":"checks/rename_column/#why-its-risky","title":"Why Its Risky","text":"<p>Renaming a column is a risky operation because:</p> <ol> <li>It can cause application errors if code, views, or triggers still reference the old column name</li> <li>It requires coordinated deployment of database changes and application changes</li> <li>May impact reports, queries, and other database objects that aren't part of the main application code</li> </ol>"},{"location":"checks/rename_column/#safer-alternative","title":"Safer Alternative","text":"<p>When renaming columns, consider:</p> <ol> <li>Two-phase deployment: First update all application code to support both old and new column names, then rename the column</li> <li>Use views: Create a view that exposes both the old and new column names during transition</li> <li>Create a new column: Instead of renaming, add a new column, copy data, and eventually drop the old column after transition</li> </ol> <p>Example safer approach:</p> <pre><code>-- 1. Keep both columns during transition \nALTER TABLE users ADD COLUMN phone_number TEXT;\nUPDATE users SET phone_number = phone;\n\n-- 2. Create a trigger to keep data in sync\nCREATE TRIGGER sync_phone_columns\nBEFORE INSERT OR UPDATE ON users\nFOR EACH ROW EXECUTE FUNCTION sync_phone_columns_func();\n\n-- 3. After application is updated, eventually drop the old column\nALTER TABLE users DROP COLUMN phone;\n</code></pre>"},{"location":"checks/rename_column/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"rename_column\"]\n\n# Override severity level\n[severity]\nrename_column = \"LOW\"  # Options: HIGH, MEDIUM, LOW, INFO\n</code></pre>"},{"location":"checks/set_not_null/","title":"Set Not Null Check","text":"<p>Check ID: <code>set_not_null</code> | Severity: MEDIUM</p>"},{"location":"checks/set_not_null/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects <code>ALTER TABLE ... ALTER COLUMN ... SET NOT NULL</code> operations which can cause table locks and data inconsistency issues.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE users ALTER COLUMN email SET NOT NULL;\n</code></pre>"},{"location":"checks/set_not_null/#why-its-risky","title":"Why Its Risky","text":"<p>Setting a NOT NULL constraint on an existing column is risky because:</p> <ol> <li>PostgreSQL must scan the entire table to verify no NULL values exist</li> <li>During this scan, an ACCESS EXCLUSIVE lock is held on the table</li> <li>For large tables, this can cause significant downtime</li> <li>If any NULL values exist, the operation will fail, potentially leaving transactions in an unexpected state</li> </ol>"},{"location":"checks/set_not_null/#safer-alternative","title":"Safer Alternative","text":"<p>Instead of directly setting NOT NULL constraints, consider:</p> <ol> <li>Verify data first: Ensure there are no NULL values before applying the constraint</li> <li>Use validation trigger: Add a trigger to prevent new NULL values while you clean up existing ones</li> <li>Apply during low-traffic periods: Schedule constraint changes during maintenance windows</li> <li>Use NOT VALID option: For check constraints, consider using NOT VALID initially</li> </ol> <p>Example safer approach:</p> <pre><code>-- 1. First check if there are any NULL values\nSELECT COUNT(*) FROM users WHERE email IS NULL;\n\n-- 2. Fix any NULL values\nUPDATE users SET email = 'unknown@example.com' WHERE email IS NULL;\n\n-- 3. Add a validation trigger to prevent new NULLs\nCREATE TRIGGER ensure_email_not_null\nBEFORE INSERT OR UPDATE ON users\nFOR EACH ROW EXECUTE FUNCTION validate_email_not_null();\n\n-- 4. Finally, add the constraint during a maintenance window\nALTER TABLE users ALTER COLUMN email SET NOT NULL;\n</code></pre>"},{"location":"checks/set_not_null/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <p>```toml</p>"},{"location":"checks/set_not_null/#disable-this-check","title":"Disable this check","text":"<p>excluded_checks = [\"set_not_null\"]</p>"},{"location":"checks/set_not_null/#override-severity-level","title":"Override severity level","text":"<p>[severity] set_not_null = \"LOW\"  # Options: HIGH, MEDIUM, LOW, INFO </p>"},{"location":"checks/truncate/","title":"Truncate Check","text":"<p>Check ID: <code>truncate</code> | Severity: HIGH</p>"},{"location":"checks/truncate/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when <code>TRUNCATE TABLE</code> statements are used. These operations can cause data loss and table locks, making them risky in production environments.</p> <p>Example risky SQL:</p> <pre><code>TRUNCATE TABLE audit_logs;\n</code></pre> <p>or</p> <pre><code>TRUNCATE audit_logs, temp_tables CASCADE;\n</code></pre>"},{"location":"checks/truncate/#why-its-risky","title":"Why Its Risky","text":"<p>Using <code>TRUNCATE TABLE</code> in PostgreSQL has several implications:</p> <ol> <li>Data Loss: <code>TRUNCATE</code> immediately removes all rows from a table without possibility of rollback (if committed)</li> <li>Locking: It acquires an ACCESS EXCLUSIVE lock on the table, blocking all concurrent access</li> <li>CASCADE Effects: With CASCADE option, it can cause unexpected data loss in related tables</li> <li>Autovacuum: Truncated tables don't need vacuuming, but may affect statistics/planning</li> <li>Transaction Visibility: Even in a transaction, other sessions may observe the truncated state due to lock acquisition</li> </ol>"},{"location":"checks/truncate/#safer-alternative","title":"Safer Alternative","text":"<p>Instead of using <code>TRUNCATE</code>, consider these alternatives:</p> <ol> <li>Use <code>DELETE FROM</code> with a <code>WHERE</code> clause to remove specific data:</li> </ol> <pre><code>DELETE FROM audit_logs WHERE created_at &lt; '2023-01-01';\n</code></pre> <ol> <li>For large tables, use batched deletes to reduce lock time:</li> </ol> <pre><code>-- Delete in batches of 10,000 rows\nDELETE FROM audit_logs \nWHERE id IN (SELECT id FROM audit_logs WHERE created_at &lt; '2023-01-01' LIMIT 10000);\n</code></pre> <ol> <li> <p>If you must clear an entire table, perform the operation during maintenance windows when application impact is minimized.</p> </li> <li> <p>Consider creating a new empty table with the same structure and then renaming tables:</p> </li> </ol> <pre><code>-- Create a new empty table with same structure\nCREATE TABLE audit_logs_new (LIKE audit_logs INCLUDING ALL);\n\n-- Switch tables\nALTER TABLE audit_logs RENAME TO audit_logs_old;\nALTER TABLE audit_logs_new RENAME TO audit_logs;\n\n-- Later, when safe\nDROP TABLE audit_logs_old;\n</code></pre>"},{"location":"checks/truncate/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"truncate\"]\n\n# Override severity level\n[severity]\ntruncate = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n\n# Custom configuration\n[truncate]\nallowed_tables = [\"test_data\", \"temp_imports\"]  # Tables that are safe to truncate\n</code></pre>"},{"location":"checks/update_without_filter/","title":"Update Without Filter Check","text":"<p>Check ID: <code>update_without_filter</code> | Severity: HIGH</p>"},{"location":"checks/update_without_filter/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects <code>UPDATE</code> statements that don't include a <code>WHERE</code> clause, which would update all rows in a table.</p> <p>Example risky SQL:</p> <pre><code>UPDATE products SET price = price * 1.1;\n</code></pre>"},{"location":"checks/update_without_filter/#why-its-risky","title":"Why Its Risky","text":"<p>Executing an UPDATE without a WHERE clause is risky because:</p> <ol> <li>It affects all rows in the table, which is rarely the intended behavior</li> <li>It can cause excessive I/O and blocking on large tables</li> <li>It may lead to unintended data changes that are difficult to reverse</li> <li>It can significantly impact application performance during execution</li> </ol>"},{"location":"checks/update_without_filter/#safer-alternative","title":"Safer Alternative","text":"<p>Always include a WHERE clause in UPDATE statements to limit the scope of changes:</p> <pre><code>-- Update specific products only\nUPDATE products SET price = price * 1.1 WHERE category = 'electronics';\n</code></pre> <p>If you genuinely need to update all rows, consider:</p> <ol> <li>Adding an explicit condition that makes the intention clear:</li> </ol> <pre><code>-- Makes it clear all rows are intentionally being updated\nUPDATE products SET last_inventory_check = CURRENT_TIMESTAMP \nWHERE TRUE;\n</code></pre> <ol> <li>For large tables, use batched updates to reduce lock time:</li> </ol> <pre><code>-- Update in smaller batches\nUPDATE products SET price = price * 1.1 \nWHERE id BETWEEN 1 AND 10000;\n</code></pre>"},{"location":"checks/update_without_filter/#configuration-options","title":"Configuration Options","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"update_without_filter\"]\n\n# Override severity level\n[severity]\nupdate_without_filter = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n\n# Custom configuration\n[update_without_filter]\nallowed_tables = [\"one_row_settings\"]  # Tables that are safe to update without WHERE\n</code></pre>"}]}