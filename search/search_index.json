{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DDLCheck","text":"<p>DDLCheck is a tool that scans PostgreSQL SQL migration files for potentially risky operations that could cause downtime, data loss, or other issues in production environments.</p>"},{"location":"#overview","title":"Overview","text":"<p>Database migrations can be risky, especially in production environments with large tables and high traffic. DDLCheck analyzes your SQL migrations to identify operations that:</p> <ul> <li>Cause table rewrites (ALTER COLUMN TYPE, DROP COLUMN)</li> <li>Acquire excessive locks (non-CONCURRENT indexes, SET NOT NULL)</li> <li>May lead to data loss (DROP TABLE, TRUNCATE)</li> <li>Affect all rows without filtering (UPDATE without WHERE)</li> </ul> <p>The goal is to help database administrators and developers make informed decisions about their migrations, avoiding unintended consequences and planning for potentially risky operations.</p>"},{"location":"#why-use-ddlcheck","title":"Why Use DDLCheck?","text":"<ul> <li>Prevent Downtime: Avoid operations that lock tables for extended periods</li> <li>Prevent Data Loss: Identify destructive operations before they run</li> <li>Education: Learn about PostgreSQL's behavior with different operations</li> <li>Best Practices: Follow community-established patterns for safer migrations</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install\npip install ddlcheck\n\n# Check a single SQL file\nddlcheck check migration.sql\n\n# Check a directory of SQL files\nddlcheck check migrations/\n\n# List all available checks\nddlcheck list-checks\n\n# Show version\nddlcheck version\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Suppose you have a migration file <code>migration.sql</code> with the following content:</p> <pre><code>-- Add a new column with NOT NULL and DEFAULT\nALTER TABLE users ADD COLUMN email_verified BOOLEAN NOT NULL DEFAULT FALSE;\n\n-- Create an index without CONCURRENTLY\nCREATE INDEX idx_users_email ON users (email);\n\n-- Update all rows without a WHERE clause\nUPDATE products SET visible = TRUE;\n</code></pre> <p>Running DDLCheck against this file:</p> <pre><code>ddlcheck check migration.sql\n</code></pre> <p>Will give you output like:</p> <pre><code>File: migration.sql\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Line \u2503 Severity \u2503 Check      \u2503 Message                                                                  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1    \u2502 HIGH     \u2502 add_column \u2502 Column 'email_verified' added to table 'users' with NOT NULL and DEFAULT \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSuggestion for add_column (line 1):\nConsider using two separate migrations:\n1. First add the column with a DEFAULT but as nullable\n2. After data has been populated, add the NOT NULL constraint\n\n... (additional output omitted) ...\n</code></pre> <p>This helps you identify potential issues before running the migration and suggests safer alternatives.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Multiple Check Types: Includes checks for various risky PostgreSQL operations</li> <li>Configurable: Customize which checks to run and their severity</li> <li>Helpful Suggestions: Provides alternatives to risky operations</li> <li>Line Numbers: Identifies exactly where issues occur</li> <li>Exit Codes: Returns non-zero exit code when issues are found (useful for CI pipelines)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation</li> <li>Available Checks</li> <li>Configuration</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! See the GitHub repository for details on how to contribute. </p>"},{"location":"configuration/","title":"Configuration","text":"<p>DDLCheck can be configured using a TOML configuration file. By default, it looks for a file named <code>.ddlcheck</code> in the current directory, but you can specify a different file using the <code>--config</code> option.</p>"},{"location":"configuration/#configuration-file-format","title":"Configuration File Format","text":"<p>DDLCheck uses TOML format for configuration. Here's an example configuration file:</p> <pre><code># List of check IDs to disable\nexcluded_checks = [\"drop_table\", \"truncate\"]\n\n# Override severity levels\n[severity]\ncreate_index = \"LOW\"\nadd_column = \"HIGH\"\n\n# Individual check configurations\n[create_index]\nignore_non_concurrent = false\nmin_size_warning = 1000  # Only warn for tables likely larger than this\n\n[update_without_filter]\nallowed_tables = [\"config\", \"settings\"]  # Tables that are safe to update without filters\n\n[truncate]\nallowed_tables = [\"logs_temp\", \"imports_staging\"]  # Tables that are safe to truncate\n</code></pre>"},{"location":"configuration/#available-configuration-options","title":"Available Configuration Options","text":""},{"location":"configuration/#global-options","title":"Global Options","text":"Option Type Description <code>excluded_checks</code> List[str] List of check IDs to disable"},{"location":"configuration/#severity-overrides","title":"Severity Overrides","text":"<p>You can override the default severity level for any check by adding a section under <code>[severity]</code>:</p> <pre><code>[severity]\ncheck_id = \"SEVERITY\"  # HIGH, MEDIUM, LOW, or INFO\n</code></pre>"},{"location":"configuration/#check-specific-options","title":"Check-Specific Options","text":""},{"location":"configuration/#createindexcheck-create_index","title":"CreateIndexCheck (<code>create_index</code>)","text":"Option Type Default Description <code>ignore_non_concurrent</code> bool <code>false</code> Completely ignore non-concurrent indexes <code>min_size_warning</code> int <code>0</code> Only warn for tables likely larger than this row count (0 means all)"},{"location":"configuration/#updatewithoutfiltercheck-update_without_filter","title":"UpdateWithoutFilterCheck (<code>update_without_filter</code>)","text":"Option Type Default Description <code>allowed_tables</code> List[str] <code>[]</code> Tables that are safe to update without WHERE clauses"},{"location":"configuration/#truncatecheck-truncate","title":"TruncateCheck (<code>truncate</code>)","text":"Option Type Default Description <code>allowed_tables</code> List[str] <code>[]</code> Tables that are safe to truncate"},{"location":"configuration/#command-line-configuration","title":"Command Line Configuration","text":"<p>You can also override some configuration options from the command line:</p> <pre><code># Exclude checks by ID\nddlcheck check --exclude add_column,drop_table migration.sql\n\n# Specify a custom config file\nddlcheck check --config my_custom_config.toml migration.sql\n\n# Enable verbose logging\nddlcheck check --verbose migration.sql\n\n# Write logs to a file\nddlcheck check --log-file ddlcheck.log migration.sql\n</code></pre>"},{"location":"configuration/#configuration-precedence","title":"Configuration Precedence","text":"<p>Configuration options are applied in the following order (each one overrides the previous):</p> <ol> <li>Default values</li> <li>Configuration file</li> <li>Command line arguments </li> </ol>"},{"location":"installation/","title":"Installation","text":"<p>DDLCheck requires Python 3.12 or newer. It's designed to be easy to install and integrate into your existing workflows.</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<p>You can install DDLCheck using pip:</p> <pre><code>pip install ddlcheck\n</code></pre> <p>This will install DDLCheck and all its dependencies.</p>"},{"location":"installation/#using-poetry","title":"Using Poetry","text":"<p>If you're using Poetry for dependency management:</p> <pre><code>poetry add ddlcheck\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<p>To install from source:</p> <pre><code>git clone https://github.com/oliverrice/ddlcheck.git\ncd ddlcheck\npip install .\n</code></pre> <p>Or with Poetry:</p> <pre><code>git clone https://github.com/oliverrice/ddlcheck.git\ncd ddlcheck\npoetry install\n</code></pre>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>Once installed, verify the installation by running:</p> <pre><code>ddlcheck --version\n</code></pre> <p>You should see the version number of DDLCheck.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>DDLCheck has the following key dependencies:</p> <ul> <li>typer: For command-line interface</li> <li>pglast: For PostgreSQL SQL parsing (PostgreSQL 17 syntax)</li> <li>rich: For colored terminal output</li> </ul> <p>These will be automatically installed when you install DDLCheck. </p>"},{"location":"checks/","title":"Available Checks","text":"<p>DDLCheck includes several checks for common database schema migration issues. Each check looks for a specific pattern in your SQL that might cause problems in production.</p>"},{"location":"checks/#check-categories","title":"Check Categories","text":"<p>The checks are organized into the following categories:</p>"},{"location":"checks/#high-severity","title":"High Severity","text":"<p>These checks identify operations that can cause significant issues:</p> <ul> <li>add_column: Detects when columns are added with NOT NULL constraints and DEFAULT values</li> <li>alter_column_type: Detects ALTER COLUMN TYPE operations that require table rewrites</li> <li>drop_table: Detects DROP TABLE operations that could result in data loss</li> <li>truncate: Detects TRUNCATE operations which can cause data loss and locks</li> <li>update_without_filter: Detects UPDATE statements without WHERE clauses</li> </ul>"},{"location":"checks/#medium-severity","title":"Medium Severity","text":"<p>These checks identify operations that can cause moderate issues:</p> <ul> <li>create_index: Detects index creation without the CONCURRENTLY option</li> <li>drop_column: Detects DROP COLUMN operations that require table rewrites</li> <li>rename_column: Detects column renames that can break dependent objects</li> <li>set_not_null: Detects when NOT NULL constraints are added to existing columns</li> </ul>"},{"location":"checks/#configuration","title":"Configuration","text":"<p>You can configure or disable any check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Exclude specific checks\nexcluded_checks = [\"truncate\", \"drop_table\"]\n\n# Override severity levels\n[severity]\ncreate_index = \"LOW\"\nadd_column = \"HIGH\"\n\n# Configure individual checks\n[create_index]\nignore_non_concurrent = false\nmin_size_warning = 1000\n\n[update_without_filter]\nallowed_tables = [\"config\", \"settings\"]\n</code></pre> <p>See the Configuration section for more details.</p>"},{"location":"checks/#custom-checks","title":"Custom Checks","text":"<p>You can create your own custom checks by implementing the <code>Check</code> base class. See the Custom Checks section for more information.</p> <pre><code>from ddlcheck.core import Check\nfrom ddlcheck.models import Issue, SeverityLevel\n\nclass MyCustomCheck(Check):\n    \"\"\"A custom check implementation.\"\"\"\n\n    @property\n    def id(self) -&gt; str:\n        return \"my_custom_check\"\n\n    @property\n    def description(self) -&gt; str:\n        return \"Detects something important\"\n\n    @property\n    def severity(self) -&gt; SeverityLevel:\n        return SeverityLevel.HIGH\n\n    def check_statement(self, stmt, line):\n        # Your implementation here\n        return []\n</code></pre>"},{"location":"checks/add_column/","title":"Add Column Check","text":"<p>Check ID: <code>add_column</code></p> <p>Severity: HIGH</p>"},{"location":"checks/add_column/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when columns are added with both a <code>NOT NULL</code> constraint and a <code>DEFAULT</code> value in the same statement.</p> <p>Example risky SQL:</p> <pre><code>ALTER TABLE users ADD COLUMN email_verified BOOLEAN NOT NULL DEFAULT FALSE;\n</code></pre>"},{"location":"checks/add_column/#why-its-risky","title":"Why It's Risky","text":"<p>When you add a column with both <code>NOT NULL</code> and <code>DEFAULT</code> constraints, PostgreSQL has to perform the following operations:</p> <ol> <li>Take an ACCESS EXCLUSIVE lock on the table (blocks all queries)</li> <li>Add the column to the table metadata</li> <li>Update every row in the table to set the default value</li> <li>Add the NOT NULL constraint</li> </ol> <p>For large tables, this can cause significant downtime because the table is locked for the entire operation. The larger the table, the longer the lock is held.</p>"},{"location":"checks/add_column/#safer-alternative","title":"Safer Alternative","text":"<p>Split this operation into two separate migrations:</p> <p>First migration:</p> <pre><code>-- Add the column as nullable with a default value\nALTER TABLE users ADD COLUMN email_verified BOOLEAN DEFAULT FALSE;\n</code></pre> <p>Second migration (after the first has been applied and data is populated):</p> <pre><code>-- Set the NOT NULL constraint separately\nALTER TABLE users ALTER COLUMN email_verified SET NOT NULL;\n</code></pre> <p>This approach:</p> <ol> <li>Adds the column with a default value which is a metadata-only operation</li> <li>Allows new rows to be inserted with the default value</li> <li>Sets the NOT NULL constraint separately, which still requires a full table scan but is a separate operation</li> </ol>"},{"location":"checks/add_column/#configuration-options","title":"Configuration Options","text":"<p>None specific to this check. </p>"},{"location":"checks/alter_column_type/","title":"Alter Column Type Check","text":"<p>The <code>alter_column_type</code> check detects when column types are changed using <code>ALTER TABLE ... ALTER COLUMN ... TYPE</code>. This operation requires a table rewrite in PostgreSQL, which can cause locks and downtime for large tables.</p>"},{"location":"checks/alter_column_type/#issue-detection","title":"Issue Detection","text":"<p>This check looks for statements like:</p> <pre><code>ALTER TABLE orders ALTER COLUMN status TYPE VARCHAR(100);\n</code></pre> <p>or statements with USING clause:</p> <pre><code>ALTER TABLE orders ALTER COLUMN amount TYPE NUMERIC(10,2) USING amount::NUMERIC(10,2);\n</code></pre>"},{"location":"checks/alter_column_type/#why-this-is-risky","title":"Why This Is Risky","text":"<p>Changing a column's data type in PostgreSQL requires rewriting the entire table because:</p> <ol> <li>PostgreSQL needs to scan every row to validate the conversion</li> <li>This operation takes an ACCESS EXCLUSIVE lock on the table</li> <li>For large tables, this can lead to significant downtime</li> <li>Applications may experience timeouts or failures during the operation</li> </ol>"},{"location":"checks/alter_column_type/#recommended-approach","title":"Recommended Approach","text":"<p>Instead of directly changing the column type, consider a multi-step approach:</p> <ol> <li>Add a new column with the desired type</li> <li>Update data in batches, populating the new column with converted values</li> <li>Update application code to use both columns during transition</li> <li>Once all data is migrated, drop the old column</li> <li>Rename the new column to the original name (if needed)</li> </ol> <p>Example:</p> <pre><code>-- Step 1: Add new column\nALTER TABLE orders ADD COLUMN status_new VARCHAR(100);\n\n-- Step 2: Fill new column in batches (do this in application code or using a cursor)\nUPDATE orders SET status_new = status::VARCHAR(100) WHERE id BETWEEN 1 AND 10000;\n-- ...repeat for all batches\n\n-- Step 3: Validation (in application code)\n\n-- Step 4: Once validated, drop old column\nALTER TABLE orders DROP COLUMN status;\n\n-- Step 5: Rename new column to original name\nALTER TABLE orders RENAME COLUMN status_new TO status;\n</code></pre>"},{"location":"checks/alter_column_type/#configuration","title":"Configuration","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"alter_column_type\"]\n\n# Override severity level\n[severity]\nalter_column_type = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n</code></pre>"},{"location":"checks/alter_column_type/#related-checks","title":"Related Checks","text":"<ul> <li>drop_column: Also detects operations requiring table rewrites</li> <li>add_column: Complements this check for schema modifications </li> </ul>"},{"location":"checks/create_index/","title":"Create Index Check","text":"<p>Check ID: <code>create_index</code></p> <p>Severity: MEDIUM</p>"},{"location":"checks/create_index/#what-it-checks-for","title":"What It Checks For","text":"<p>This check detects when indexes are created without the <code>CONCURRENTLY</code> option.</p> <p>Example risky SQL:</p> <pre><code>CREATE INDEX idx_users_email ON users (email);\n</code></pre>"},{"location":"checks/create_index/#why-its-risky","title":"Why It's Risky","text":"<p>When you create an index without the <code>CONCURRENTLY</code> option, PostgreSQL takes an <code>EXCLUSIVE</code> lock on the table while building the index. This lock blocks all writes to the table (such as INSERT, UPDATE, DELETE operations) until the index is fully built.</p> <p>For large tables, index creation can take a long time, potentially causing:</p> <ol> <li>Application timeouts or failures due to blocked write operations</li> <li>Growing lock queues that affect database performance </li> <li>Elevated latency for application queries</li> </ol>"},{"location":"checks/create_index/#safer-alternative","title":"Safer Alternative","text":"<p>Use the <code>CONCURRENTLY</code> option when creating indexes in production:</p> <pre><code>CREATE INDEX CONCURRENTLY idx_users_email ON users (email);\n</code></pre> <p>The <code>CONCURRENTLY</code> option:</p> <ol> <li>Uses a less restrictive lock that allows writes to continue</li> <li>Takes longer to complete since it does multiple passes over the table</li> <li>Cannot be used within a transaction block</li> </ol> <p>Note that <code>CREATE INDEX CONCURRENTLY</code> is more expensive and slower but greatly reduces the impact on active production applications.</p>"},{"location":"checks/create_index/#important-limitations","title":"Important Limitations","text":"<p>When using <code>CREATE INDEX CONCURRENTLY</code>:</p> <ol> <li>You cannot use it inside a transaction block</li> <li>If the operation fails, you may be left with an invalid index that needs to be dropped</li> <li>It places a higher load on the database during creation</li> </ol>"},{"location":"checks/create_index/#configuration-options","title":"Configuration Options","text":"<p>No specific configuration options for this check. </p>"},{"location":"checks/truncate/","title":"Truncate Check","text":"<p>The <code>truncate</code> check detects when <code>TRUNCATE TABLE</code> statements are used. These operations can cause data loss and table locks, making them risky in production environments.</p>"},{"location":"checks/truncate/#issue-detection","title":"Issue Detection","text":"<p>This check looks for statements like:</p> <pre><code>TRUNCATE TABLE audit_logs;\n</code></pre> <p>or</p> <pre><code>TRUNCATE audit_logs, temp_tables CASCADE;\n</code></pre>"},{"location":"checks/truncate/#why-this-is-risky","title":"Why This Is Risky","text":"<p>Using <code>TRUNCATE TABLE</code> in PostgreSQL has several implications:</p> <ol> <li>Data Loss: <code>TRUNCATE</code> immediately removes all rows from a table without possibility of rollback (if committed)</li> <li>Locking: It acquires an ACCESS EXCLUSIVE lock on the table, blocking all concurrent access</li> <li>CASCADE Effects: With CASCADE option, it can cause unexpected data loss in related tables</li> <li>Autovacuum: Truncated tables don't need vacuuming, but may affect statistics/planning</li> <li>Transaction Visibility: Even in a transaction, other sessions may observe the truncated state due to lock acquisition</li> </ol>"},{"location":"checks/truncate/#recommended-approach","title":"Recommended Approach","text":"<p>Instead of using <code>TRUNCATE</code>, consider these alternatives:</p> <ol> <li>Use <code>DELETE FROM</code> with a <code>WHERE</code> clause to remove specific data:</li> </ol> <pre><code>DELETE FROM audit_logs WHERE created_at &lt; '2023-01-01';\n</code></pre> <ol> <li>For large tables, use batched deletes to reduce lock time:</li> </ol> <pre><code>-- Delete in batches of 10,000 rows\nDELETE FROM audit_logs \nWHERE id IN (SELECT id FROM audit_logs WHERE created_at &lt; '2023-01-01' LIMIT 10000);\n</code></pre> <ol> <li> <p>If you must clear an entire table, perform the operation during maintenance windows when application impact is minimized.</p> </li> <li> <p>Consider creating a new empty table with the same structure and then renaming tables:</p> </li> </ol> <pre><code>-- Create a new empty table with same structure\nCREATE TABLE audit_logs_new (LIKE audit_logs INCLUDING ALL);\n\n-- Switch tables\nALTER TABLE audit_logs RENAME TO audit_logs_old;\nALTER TABLE audit_logs_new RENAME TO audit_logs;\n\n-- Later, when safe\nDROP TABLE audit_logs_old;\n</code></pre>"},{"location":"checks/truncate/#configuration","title":"Configuration","text":"<p>You can configure or disable this check in your <code>.ddlcheck</code> configuration file:</p> <pre><code># Disable this check\nexcluded_checks = [\"truncate\"]\n\n# Override severity level\n[severity]\ntruncate = \"MEDIUM\"  # Options: HIGH, MEDIUM, LOW, INFO\n\n# Custom configuration\n[truncate]\nallowed_tables = [\"test_data\", \"temp_imports\"]  # Tables that are safe to truncate\n</code></pre>"},{"location":"checks/truncate/#related-checks","title":"Related Checks","text":"<ul> <li>drop_table: Similar destructive operation</li> <li>update_without_filter: Another operation that affects all rows </li> </ul>"}]}